{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dccff8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CHARGEMENT ####\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_df = pd.read_csv(\"X_train.csv\")\n",
    "y_train_df = pd.read_csv(\"y_train.csv\")\n",
    "data = X_train_df.merge(y_train_df, on=\"ROW_ID\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5528e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATION FEATURES DE BASE ie lignes par lignes ####\n",
    "\n",
    "def create_base_features(df):\n",
    "    ret_cols = [f'RET_{i}' for i in range(1, 21)]\n",
    "    vol_cols = [f'SIGNED_VOLUME_{i}' for i in range(1, 21)]\n",
    "\n",
    "    # Premières features\n",
    "    df[\"RET_MEAN\"] = df[ret_cols].mean(axis=1)\n",
    "    df[\"RET_STD\"] = df[ret_cols].std(axis=1)\n",
    "    df[\"RET_MEDIAN\"] = df[ret_cols].median(axis=1)\n",
    "    df[\"RET_SKEW\"] = df[ret_cols].skew(axis=1)\n",
    "    df[\"RET_KURT\"] = df[ret_cols].kurtosis(axis=1)\n",
    "    \n",
    "    # TO CHECK :\n",
    "    x = np.arange(len(ret_cols))\n",
    "    df['RET_MOMENTUM'] = df[ret_cols].apply(lambda y: np.polyfit(x, y.fillna(0), 1)[0], axis=1)\n",
    "    # \n",
    "\n",
    "    df[\"VOL_MEAN\"] = df[vol_cols].mean(axis=1)\n",
    "    df[\"VOL_STD\"] = df[vol_cols].std(axis=1)\n",
    "    df[\"SHARPE_RATIO_PROXY\"] = df[\"RET_MEAN\"] / (df[\"RET_STD\"] + 1e-6)\n",
    "    \n",
    "    for w in [5, 10]:\n",
    "        ret_window = ret_cols[:w]\n",
    "        df[f\"RET_AVG_{w}\"] = df[ret_window].mean(axis=1)\n",
    "        df[f\"RET_STD_{w}\"] = df[ret_window].std(axis=1)\n",
    "        df[f\"RET_MEDIAN_{w}\"] = df[ret_window].median(axis=1)\n",
    "    return df\n",
    "\n",
    "data = create_base_features(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5abbe983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 1: 0.5709451024993758\n",
      "Score 2: 0.5735526644289717\n",
      "Score 3: 0.5808760298482621\n",
      "Score 4: 0.5777691475491692\n",
      "Score 5: 0.5765485866459541\n",
      "GLOBAL 0.5759383061943466\n"
     ]
    }
   ],
   "source": [
    "#### ENTRAINEMENT, StratifiedKFold ####\n",
    "\n",
    "data['y_binary'] = (data['target'] > 0).astype(int)\n",
    "\n",
    "\n",
    "base_original_features = [f'RET_{i}' for i in range(1, 21)] + [f'SIGNED_VOLUME_{i}' for i in range(1, 21)] + ['AVG_DAILY_TURNOVER']\n",
    "base_created_features = ['RET_MEAN', 'RET_STD', 'RET_MEDIAN', 'RET_SKEW', 'RET_KURT', 'RET_MOMENTUM', \n",
    "                         'VOL_MEAN', 'VOL_STD', 'SHARPE_RATIO_PROXY', 'RET_AVG_5', 'RET_AVG_10', \n",
    "                         \"RET_STD_10\", \"RET_STD_5\", \"RET_MEDIAN_10\", \"RET_MEDIAN_5\"]\n",
    "feature_cols = base_original_features + base_created_features + ['TS'] \n",
    "\n",
    "\n",
    "\n",
    "X = data[feature_cols].copy()\n",
    "y = data['y_binary']\n",
    "\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_preds = np.zeros(len(data))\n",
    "models = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx].copy(), y.iloc[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx].copy(), y.iloc[val_idx]\n",
    "\n",
    "    
    "    for w in [5, 10]:\n",
    "        # Calculer les mappings sur le set d'entraînemen\n",
    "        mean_map = X_train.groupby('TS')[f'RET_AVG_{w}'].mean()\n",
    "        median_map = X_train.groupby('TS')[f'RET_AVG_{w}'].median()\n",
    "        std_map = X_train.groupby('TS')[f'RET_AVG_{w}'].std()\n",
    "        q1_map = X_train.groupby('TS')[f'RET_AVG_{w}'].quantile(0.25) \n",
    "        q3_map = X_train.groupby('TS')[f'RET_AVG_{w}'].quantile(0.75)\n",
    "        \n",
    "        # Appliquer les mappings à X_train et X_val\n",
    "        X_train.loc[:, f'GLOBAL_AVG_RET_{w}'] = X_train['TS'].map(mean_map)\n",
    "        X_val.loc[:, f'GLOBAL_AVG_RET_{w}'] = X_val['TS'].map(mean_map).fillna(X_train[f'RET_AVG_{w}'].mean())\n",
    "\n",
    "        X_train.loc[:, f'GLOBAL_MEDIAN_RET_{w}'] = X_train['TS'].map(median_map)\n",
    "        X_val.loc[:, f'GLOBAL_MEDIAN_RET_{w}'] = X_val['TS'].map(median_map).fillna(X_train[f'RET_AVG_{w}'].median())\n",
    "\n",
    "        X_train.loc[:, f'GLOBAL_STD_RET_{w}'] = X_train['TS'].map(std_map)\n",
    "        X_val.loc[:, f'GLOBAL_STD_RET_{w}'] = X_val['TS'].map(std_map).fillna(X_train[f'RET_AVG_{w}'].std())\n",
    "\n",
    "        # X_train.loc[:, f'GLOBAL_Q1_RET_{w}'] = X_train['TS'].map(q1_map) \n",
    "        # X_val.loc[:, f'GLOBAL_Q1_RET_{w}'] = X_val['TS'].map(q1_map).fillna(X_train[f'RET_AVG_{w}'].quantile(0.25)) \n",
    "\n",
    "        # X_train.loc[:, f'GLOBAL_Q3_RET_{w}'] = X_train['TS'].map(q3_map) \n",
    "        # X_val.loc[:, f'GLOBAL_Q3_RET_{w}'] = X_val['TS'].map(q3_map).fillna(X_train[f'RET_AVG_{w}'].quantile(0.75)) \n",
    "    \n",
    "    # Nettoyer les colonnes TS avant l'entraînement\n",
    "    X_train_final = X_train.drop(columns=['TS'])\n",
    "    X_val_final = X_val.drop(columns=['TS'])\n",
    "    \n",
    "    # TO DO : checker les hyperparameters \n",
    "    model = xgb.XGBClassifier(n_estimators=1000, max_depth=4, learning_rate=0.05, subsample=0.8,\n",
    "                              colsample_bytree=0.8, gamma=0.1, random_state=42, n_jobs=-1,\n",
    "                              early_stopping_rounds=50)\n",
    "    \n",
    "    model.fit(X_train_final, y_train, eval_set=[(X_val_final, y_val)], verbose=False)\n",
    "              \n",
    "    val_preds = model.predict(X_val_final)\n",
    "    oof_preds[val_idx] = val_preds\n",
    "    models.append(model)\n",
    "    print(f\"Score {fold+1}: {accuracy_score(y_val, val_preds)}\")\n",
    "    \n",
    "print(f\"GLOBAL {accuracy_score(y, oof_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f30f84c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"GLOBAL_Q1_RET_10\" in feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57e081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création du fichier submission.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yp/c6z3dm3s1s1dx6tz47yy15gc0000gn/T/ipykernel_6858/1261001567.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "/var/folders/yp/c6z3dm3s1s1dx6tz47yy15gc0000gn/T/ipykernel_6858/1261001567.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#### CREATION DU CSV DE TEST ####\n",
    "\n",
    "X_test_df = pd.read_csv(\"X_test.csv\")\n",
    "X_test_featured = create_base_features(X_test_df.copy())\n",
    "\n",
    "for w in [5, 10]:\n",
    "    mean_map_full_train = X.groupby('TS')[f'RET_AVG_{w}'].mean()\n",
    "    median_map_full_train = X.groupby('TS')[f'RET_AVG_{w}'].median()\n",
    "    std_map_full_train = X.groupby('TS')[f'RET_AVG_{w}'].std()\n",
    "    q1_map_full_train = X.groupby('TS')[f'RET_AVG_{w}'].quantile(0.25)\n",
    "    q3_map_full_train = X.groupby('TS')[f'RET_AVG_{w}'].quantile(0.75)\n",
    "    \n",
    "    X_test_featured[f'GLOBAL_AVG_RET_{w}'] = X_test_featured['TS'].map(mean_map_full_train).fillna(X[f'RET_AVG_{w}'].mean())\n",
    "    X_test_featured[f'GLOBAL_MEDIAN_RET_{w}'] = X_test_featured['TS'].map(median_map_full_train).fillna(X[f'RET_AVG_{w}'].median())\n",
    "    X_test_featured[f'GLOBAL_STD_RET_{w}'] = X_test_featured['TS'].map(std_map_full_train).fillna(X[f'RET_AVG_{w}'].std())\n",
    "    # X_test_featured[f'GLOBAL_Q1_RET_{w}'] = X_test_featured['TS'].map(q1_map_full_train).fillna(X[f'RET_AVG_{w}'].quantile(0.25))\n",
    "    # X_test_featured[f'GLOBAL_Q3_RET_{w}'] = X_test_featured['TS'].map(q3_map_full_train).fillna(X[f'RET_AVG_{w}'].quantile(0.75))\n",
    "\n",
    "# Sélectionner les colonnes finales et nettoyer\n",
    "stats_to_add = ['AVG', 'MEDIAN', 'STD', 'Q1', 'Q3']\n",
    "unwanted_cols = []\n",
    "unwanted_cols +=  ['Q1', \"Q3\"] \n",
    "stats_to_add = [elt for elt in stats_to_add if elt not in unwanted_cols]\n",
    "\n",
    "new_global_features = [f'GLOBAL_{stat}_RET_{w}' for stat in stats_to_add for w in [5, 10]]\n",
    "final_feature_cols = base_original_features + base_created_features + new_global_features\n",
    "X_test = X_test_featured[final_feature_cols]\n",
    "\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "\n",
    "model_feature_names = models[0].get_booster().feature_names # liste ordonéee des variables utilisées\n",
    "X_test = X_test[model_feature_names] # on a le meme ordre\n",
    "\n",
    "# la moyenne des 5 modèles \n",
    "test_preds_probas = []\n",
    "for i, model in enumerate(models):\n",
    "    probas = model.predict_proba(X_test)[:, 1]\n",
    "    test_preds_probas.append(probas)\n",
    "\n",
    "avg_probas = np.mean(test_preds_probas, axis=0)\n",
    "final_preds = (avg_probas > 0.5).astype(int)\n",
    "\n",
    "# Création du fichier de soumission\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ROW_ID': X_test_df['ROW_ID'],\n",
    "    'prediction': final_preds\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bd22874a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2750)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(submission_df[\"prediction\"]==1).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
